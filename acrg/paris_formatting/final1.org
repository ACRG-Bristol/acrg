#+property: header-args:jupyter-python :kernel pymc_venv :session py

#+BEGIN_SRC jupyter-python
  %load_ext autoreload
  %autoreload 2
#+END_SRC

#+RESULTS:

#+begin_src jupyter-python :tangle final1.py
from pathlib import Path
import re

import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pymc as pm
import sparse
import xarray as xr
#+end_src

#+RESULTS:

* Getting files and traces
  :PROPERTIES:
  :CUSTOM_ID: getting-files-and-traces
  :END:

#+BEGIN_SRC jupyter-python :tangle final1.py
  from file_processing import get_netcdf_files, get_rhime_outs
  from helpers import get_prior_samples
#+END_SRC

#+RESULTS:


#+BEGIN_SRC jupyter-python :tangle final1.py
  species = "sf6"
  files = get_netcdf_files("/home/brendan/Documents/inversions/plotting/sf6_best", filename_search="SF6")
#+END_SRC

#+RESULTS:

#+begin_src jupyter-python :tangle final1.py
  outs = get_rhime_outs(files)
#+end_src
#+RESULTS:


#+BEGIN_SRC jupyter-python
for k, v in  outs[0].attrs.items():
    print(f"{k}: {v}")
#+END_SRC

#+RESULTS:
#+begin_example
Start date: 2020-06-01
End date: 2020-07-01
Latent sampler: mc.nuts.NUTS
Hyper sampler: licer.Slice o
Burn in: 10000
Tuning steps: 10000
Number of chains: 4
Error for each site: True
Emissions Prior: pdf,truncatednormal,mu,-1706.68549918,sigma,41.34586525,lower,0.0
Model error Prior: pdf,uniform,lower,0.1,upper,1.0
BCs Prior: pdf,truncatednormal,mu,1.0,sigma,0.03,lower,0.0
Creator: bm13805
Date created: 2024-01-09 10:33:53.036470
Convergence: Passed
Repository version:
#+end_example

* Sampling from model

#+BEGIN_SRC jupyter-python :tangle final1.py
  def get_prior_from_attrs(x):
      prior = {}
      split = x.split(",")
      for k, v in zip(split[::2], split[1::2]):
          prior[k] = v if k == "pdf" else float(v)
      return prior
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python :tangle final1.py
  sampling_kwargs = dict(xprior = get_prior_from_attrs(outs[0].attrs["Emissions Prior"]),
                         bcprior = get_prior_from_attrs(outs[0].attrs["BCs Prior"]),
                         min_model_error = 0.15)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python :async yes :tangle final1.py
  prior_samples = [get_prior_samples(ds, **sampling_kwargs).prior.squeeze(drop=True) for ds in outs]
#+END_SRC

#+RESULTS:
#+begin_example
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
Sampling: [bc, sigma, x, ymod, ymodbc]
#+end_example

#+BEGIN_SRC jupyter-python
  prior_samples[0]
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:      (draw: 1000, nparam: 97, nmeasure: 877, nBC: 16,
                  nsigma_site: 8, nsigma_time: 4)
Coordinates:
  ,* draw         (draw) int64 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999
  ,* nparam       (nparam) int64 0 1 2 3 4 5 6 7 8 ... 88 89 90 91 92 93 94 95 96
  ,* nmeasure     (nmeasure) int64 0 1 2 3 4 5 6 ... 870 871 872 873 874 875 876
  ,* nBC          (nBC) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
  ,* nsigma_site  (nsigma_site) int64 0 1 2 3 4 5 6 7
  ,* nsigma_time  (nsigma_time) int64 0 1 2 3
Data variables:
    x            (draw, nparam) float64 0.2698 0.2837 0.7137 ... 0.5792 0.826
    ymod         (draw, nmeasure) float64 10.13 9.938 10.19 ... 10.43 10.02
    bc           (draw, nBC) float64 1.024 0.9837 1.02 ... 0.9767 1.001 0.9635
    sigma        (draw, nsigma_site, nsigma_time) float64 0.706 0.26 ... 0.859
    ymodbc       (draw, nmeasure) float64 10.16 10.15 10.21 ... 9.846 10.18
Attributes:
    created_at:                 2024-01-22T09:34:58.660486
    arviz_version:              0.16.1
    inference_library:          pymc
    inference_library_version:  5.10.0
#+end_example


** Checking if inversions Y errors are calculated correctly...
  :PROPERTIES:
  :CUSTOM_ID: checking-if-inversions-y-errors-are-calculated-correctly
  :END:

#+BEGIN_SRC jupyter-python
  trace = az.InferenceData.from_netcdf("/home/brendan/Documents/inversions/plotting/sf6_best/trace_hbmcmc_output_2020-06-01.nc")
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  hbmcmc = xr.open_dataset("/home/brendan/Documents/inversions/plotting/sf6_best/SF6_EUROPE_hbmcmc_output_2020-06-01.nc")
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  trace
#+END_SRC

#+RESULTS:
: Inference data with groups:
: 	> posterior
: 	> log_likelihood
: 	> sample_stats
: 	> observed_data

#+BEGIN_SRC jupyter-python
  from helpers import get_rhime_model
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  model = get_rhime_model(hbmcmc, bc_name="xbc", sigma_name="sig", **sampling_kwargs)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  model
#+END_SRC

#+RESULTS:
#+begin_export latex
$$
            \begin{array}{rcl}
            \text{x} &\sim & \operatorname{TruncatedNormal}(-1.71e+03,~41.3,~0,~inf)\\\text{xbc} &\sim & \operatorname{TruncatedNormal}(1,~0.03,~0,~inf)\\\text{sig} &\sim & \operatorname{Uniform}(0.1,~1)\\\text{ymodbc} &\sim & \operatorname{Normal}(f(\text{xbc}),~f(\text{sig},~\text{x}))\\\text{ymod} &\sim & \operatorname{Normal}(f(\text{x},~\text{xbc}),~f(\text{sig},~\text{x}))
            \end{array}
            $$
#+end_export


#+BEGIN_SRC jupyter-python :async yes
  post_pred = pm.sample_posterior_predictive(trace, model=model, var_names=["ymodbc", "ymod"])
#+END_SRC

#+RESULTS:
:RESULTS:
: Sampling: [ymod, ymodbc]
: <IPython.core.display.HTML object>
: <IPython.core.display.HTML object>
:END:

#+BEGIN_SRC jupyter-python
  post_pred
#+END_SRC

#+RESULTS:
: Inference data with groups:
: 	> posterior_predictive

** Plotting
   :PROPERTIES:
   :CUSTOM_ID: plotting
   :END:

#+BEGIN_SRC jupyter-python
  colors = ['navy','firebrick','dodgerblue','darkorange']
  font = {'size':12}
  plt.rc('font', **font)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  def plot_timeseries(time, values, uncert_lower=None, uncert_upper=None, color=None, label=None, ax=None, monthly=True, errorbar=True, **kwargs):
      """Plot time series"""
      if ax is None:
          ax = plt.gca()
      plot_kwargs = kwargs
      if color:
          plot_kwargs['color'] = color
      if label:
          plot_kwargs['label'] = label
      if monthly:
          time = time.astype('datetime64[M]')
      ax.plot(time, values, **plot_kwargs)
      if label:
          del plot_kwargs['label']
      if uncert_lower is not None and uncert_upper is not None:
          if errorbar:
              ax.errorbar(time, values, yerr=[values - uncert_lower, uncert_upper - values], marker='o', alpha=0.6, **plot_kwargs)
          ax.fill_between(time, uncert_lower, uncert_upper, alpha=0.2, **plot_kwargs)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  filt = hbmcmc.siteindicator == 0
  hbmcmc0 = hbmcmc.where(filt, drop=True)
  post_pred0 = post_pred.posterior_predictive.ymod.where(filt, drop=True)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  pp_mean = post_pred0.mean(["chain", "draw"])
  pp_hdi = az.hdi(post_pred0, 0.68)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  pp_mean
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.DataArray 'ymod' (nmeasure: 180)>
array([10.42254861, 10.43379036, 10.43020523, 10.43241513, 10.42616951,
       10.41934813, 10.41899307, 10.42727969, 10.46678644, 10.44538824,
       10.45249775, 10.44319071, 10.44459472, 10.4509421 , 10.4308287 ,
       10.42625893, 10.42749069, 10.42692864, 10.44163816, 10.43398267,
       10.43363096, 10.44008081, 10.44105546, 10.43027318, 10.43252076,
       10.43567825, 10.42932216, 10.43207578, 10.43377744, 10.43396595,
       10.43572657, 10.43393851, 10.44230718, 10.44040444, 10.43734199,
       10.42891949, 10.42747058, 10.45725672, 10.43619904, 10.43564415,
       10.43448175, 10.43445229, 10.4333969 , 10.46414208, 10.4371541 ,
       10.43709024, 10.44144245, 10.42754776, 10.42865415, 10.43603475,
       10.43873128, 10.45407569, 10.47854705, 10.47564972, 10.46622215,
       10.4506168 , 10.459006  , 10.46461614, 10.46430858, 10.43298232,
       10.42129509, 10.42957069, 10.4300716 , 10.43837966, 10.44769284,
       10.45468273, 10.44908527, 10.44884619, 10.462096  , 10.46040144,
       10.45618084, 10.53564069, 10.69182477, 10.70608538, 10.7091179 ,
       10.60603162, 10.61072666, 10.6045714 , 10.5387145 , 10.55461373,
       10.62724583, 10.6322111 , 10.62017127, 10.61584488, 10.59434896,
       10.60155535, 10.62865679, 10.60463518, 10.54704447, 10.53470192,
       10.53209276, 10.53874986, 10.56262081, 10.5330626 , 10.50951979,
       10.4908203 , 10.50336947, 10.51860209, 10.50829289, 10.50985262,
       10.49464768, 10.48931692, 10.4933549 , 10.49157322, 10.4665395 ,
       10.46860347, 10.48653176, 10.51191951, 10.52597323, 10.53751073,
       10.54473716, 10.5547454 , 10.50545231, 10.48012788, 10.4773272 ,
       10.4833808 , 10.47216384, 10.49032321, 10.49453751, 10.5049127 ,
       10.52935503, 10.49681638, 10.48055419, 10.4663577 , 10.45928109,
       10.45803309, 10.45861323, 10.48281064, 10.47687809, 10.47479184,
       10.48172136, 10.4842709 , 10.48675755, 10.49829732, 10.4946354 ,
       10.48682464, 10.50431225, 10.50433925, 10.50724336, 10.52526323,
       10.53081989, 10.52927331, 10.57482366, 10.59899635, 10.5161965 ,
       10.50967829, 10.51547648, 10.58352713, 10.66275829, 10.6615505 ,
       10.67556385, 10.68133379, 10.67446453, 10.68224354, 10.62975786,
       10.59133363, 10.47750268, 10.49888259, 10.48546821, 10.48165904,
       10.45973408, 10.46228844, 10.47787085, 10.48796482, 10.49013635,
       10.4851585 , 10.47274651, 10.46919343, 10.47276421, 10.46229211,
       10.45813124, 10.46353432, 10.47256112, 10.48057001, 10.49302762,
       10.49643703, 10.48277598, 10.47179261, 10.47057853, 10.46123437])
Coordinates:
  ,* nmeasure    (nmeasure) int64 0 1 2 3 4 5 6 7 ... 173 174 175 176 177 178 179
    measurenum  (nmeasure) int64 0 1 2 3 4 5 6 7 ... 173 174 175 176 177 178 179
#+end_example

#+BEGIN_SRC jupyter-python
  fig, ax = plt.subplots(1, figsize=(14,7), constrained_layout=True)

  plot_timeseries(hbmcmc0.Ytime.values,
                  hbmcmc0.Ymodmean.values,
                  uncert_lower=hbmcmc0.Ymod68.isel(nUI=0),
                  uncert_upper=hbmcmc0.Ymod68.isel(nUI=1),
                  color=colors[0], label="hbmcmc y post pred", ax=ax, monthly=False, errorbar=False)
  plot_timeseries(hbmcmc0.Ytime.values,
                  pp_mean.values,
                  uncert_lower=pp_hdi.ymod.isel(hdi=0).values,
                  uncert_upper=pp_hdi.ymod.isel(hdi=1).values,
                  color=colors[1], label="sampled y post pred", ax=ax, monthly=False, errorbar=False)
                          
  ax.legend()

  fig.suptitle("Posterior predictives: RHIME vs. sampling posterior predictive")
#+END_SRC

#+RESULTS:
:RESULTS:
: Text(0.5, 0.98, 'Posterior predictives: RHIME vs. sampling posterior predictive')
[[file:./.ob-jupyter/dd377902496beb390157665ddeaedcec22630bbb.png]]
:END:

** TODO sampling from posterior predictive
#+begin_src jupyter-python

#+end_src
** Example: combine posterior and prior traces

#+begin_src jupyter-python
xr.merge([outs[0][[dv for dv in outs[0].data_vars if "trace" in dv]], prior_samples[0].rename_vars({dv: str(dv) + "_prior" for dv in prior_samples[0].data_vars})])
#+end_src

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:       (draw: 10000, nBC: 16, nsigma_time: 4, nsigma_site: 8,
                   nparam: 97, nmeasure: 877)
Coordinates:
  ,* draw          (draw) int64 0 1 2 3 4 5 6 ... 9994 9995 9996 9997 9998 9999
  ,* nBC           (nBC) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
  ,* nsigma_time   (nsigma_time) int64 0 1 2 3
  ,* nsigma_site   (nsigma_site) int64 0 1 2 3 4 5 6 7
  ,* nparam        (nparam) int64 0 1 2 3 4 5 6 7 8 ... 89 90 91 92 93 94 95 96
  ,* nmeasure      (nmeasure) int64 0 1 2 3 4 5 6 ... 870 871 872 873 874 875 876
Data variables:
    xtrace        (draw, nparam) float64 ...
    bctrace       (draw, nBC) float64 ...
    sigtrace      (draw, nsigma_site, nsigma_time) float64 ...
    x_prior       (draw, nparam) float64 0.2698 0.2837 0.7137 ... nan nan nan
    ymod_prior    (draw, nmeasure) float64 10.13 9.938 10.19 ... nan nan nan
    bc_prior      (draw, nBC) float64 1.024 0.9837 1.02 1.046 ... nan nan nan
    sigma_prior   (draw, nsigma_site, nsigma_time) float64 0.706 0.26 ... nan
    ymodbc_prior  (draw, nmeasure) float64 10.16 10.15 10.21 ... nan nan nan
Attributes: (12/15)
    Start date:           2020-06-01
    End date:             2020-07-01
    Latent sampler:       mc.nuts.NUTS
    Hyper sampler:        licer.Slice o
    Burn in:              10000
    Tuning steps:         10000
    ...                   ...
    Model error Prior:    pdf,uniform,lower,0.1,upper,1.0
    BCs Prior:            pdf,truncatednormal,mu,1.0,sigma,0.03,lower,0.0
    Creator:              bm13805
    Date created:         2024-01-09 10:33:53.036470
    Convergence:          Passed
    Repository version:
#+end_example

* Merge traces
#+begin_src jupyter-python :tangle final1.py
def combine_outs_and_prior_samples(outs: xr.Dataset, prior_samples: xr.Dataset) -> xr.Dataset:
    """Combine trace variables from RHIME outputs and prior samples."""
    trace_dvs = [dv for dv in outs.data_vars if "trace" in dv]
    prior_rename_dict = {dv: str(dv) + "_prior" for dv in prior_samples.data_vars}
    return xr.merge([outs[trace_dvs], prior_samples.rename_vars(prior_rename_dict)])
#+end_src

#+RESULTS:
NOTE: there are far more samples in the RHIME output traces, so this might use more memory than necessary...


Now let's apply this function to all of the outs and prior samples:
#+begin_src jupyter-python :tangle final1.py
all_traces = [combine_outs_and_prior_samples(outs_ds, prior_samples_ds) for outs_ds, prior_samples_ds in zip(outs, prior_samples)]
#+end_src

#+RESULTS:

* Country totals

** Get country files
#+begin_src jupyter-python :tangle final1.py
inversions_path = Path("/home/brendan/Documents/inversions/openghg_inversions/")
countries = xr.open_dataset(inversions_path / "countries" / "country_EUROPE.nc")
countries_ukmo = xr.open_dataset(inversions_path / "countries" / "country-ukmo_EUROPE.nc")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
countries_ukmo
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:  (lon: 391, lat: 293, ncountries: 20)
: Coordinates:
:   * lon      (lon) float32 -97.9 -97.55 -97.2 -96.84 ... 38.32 38.68 39.03 39.38
:   * lat      (lat) float32 10.73 10.96 11.2 11.43 ... 78.36 78.59 78.82 79.06
: Dimensions without coordinates: ncountries
: Data variables:
:     name     (ncountries) <U14 ...
:     country  (lat, lon) int32 ...

** Get x-to-country matrices
#+begin_src jupyter-python :async yes :tangle final1.py
from helpers import get_x_to_country_mat, get_area_grid_data_array

area_grid = get_area_grid_data_array(outs[0].lat, outs[0].lon)

country_mats = [get_x_to_country_mat(countries, hbmcmc_outs=outs_ds, area_grid=area_grid, basis_cat_dim="nparam") for outs_ds in outs]
country_ukmo_mats = [get_x_to_country_mat(countries_ukmo, hbmcmc_outs=outs_ds, area_grid=area_grid, basis_cat_dim="nparam") for outs_ds in outs]
#+end_src

#+RESULTS:

#+begin_src jupyter-python
country_mats[0]
#+end_src

#+RESULTS:
#+begin_example
<xarray.DataArray (ncountries: 104, nparam: 97)>
array([[1.26864295e-03, 1.66419634e-03, 0.00000000e+00, ...,
        5.31429429e-04, 1.33350244e-04, 9.77955867e-05],
       [3.06981430e-04, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       ...,
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])
Coordinates:
    country  (ncountries) <U52 ...
  ,* nparam   (nparam) int64 0 1 2 3 4 5 6 7 8 9 ... 88 89 90 91 92 93 94 95 96
Dimensions without coordinates: ncountries
#+end_example

** Get country traces
#+begin_src jupyter-python :async yes :tangle final1.py
from helpers import get_country_trace

country_traces = [get_country_trace("sf6", x_trace=traces[["xtrace", "x_prior"]], x_to_country=mat) for traces, mat in zip(all_traces, country_mats)]
country_ukmo_traces = [get_country_trace("sf6", x_trace=traces[["xtrace", "x_prior"]], x_to_country=mat) for traces, mat in zip(all_traces, country_ukmo_mats)]
#+end_src

#+RESULTS:

** Select countries and concatenate
Filters for which countries to choose from the two country files.
#+begin_src jupyter-python :tangle final1.py
paris_countries = [
    "BELGIUM",
    "SWITZERLAND",
    "AUSTRIA",
    "ITALY",
    "NETHERLANDS",
    "CZECHIA",
    "POLAND",
    "HUNGARY",
    "SLOVAKIA",
    "SWEDEN",
    "FINLAND",
]
country_filt = countries.name.isin(paris_countries)

paris_countries_ukmo = ["BENELUX", "RestEU", "SpaPor", "IRELAND", "UNITED KINGDOM", "FRANCE", "GERMANY", "DENMARK", "NORWAY"]
country_ukmo_filt = countries_ukmo.name.isin(paris_countries_ukmo)
#+end_src

#+RESULTS:

Times to use for concatenating:
#+begin_src jupyter-python :tangle final1.py
times = [ds.Ytime.min().values for ds in outs]
#+end_src

#+RESULTS:

Filter, concatenate along time, then concatenate along ~ncountries~:
#+begin_src jupyter-python :async yes :tangle final1.py
country_traces_concat = xr.concat([trace.where(country_filt, drop=True).expand_dims({"time": [time]}) for trace, time in zip(country_traces, times)], dim="time")
country_ukmo_traces_concat = xr.concat([trace.where(country_ukmo_filt, drop=True).expand_dims({"time": [time]}) for trace, time in zip(country_ukmo_traces, times)], dim="time")
country_traces_merged = xr.concat([country_traces_concat, country_ukmo_traces_concat], dim="ncountries")
#+end_src

#+RESULTS:


** Calculate mean, mode, quantiles, and combine

#+begin_src jupyter-python :async yes :tangle final1.py
from helpers import make_quantiles, calc_mode

def calculate_stats(ds: xr.Dataset, name: str, chunk_dim: str, chunk_size: int = 10) -> xr.Dataset:
    output = [
        ds.xtrace.mean("draw").rename(f"{name}apost"),
        calc_mode(ds.xtrace.chunk({chunk_dim: chunk_size}), sample_dim="draw").compute().rename(f"{name}apost_mode"),
        make_quantiles(ds.xtrace, sample_dim="draw").rename(f"q{name}apost"),
        ds.x_prior.mean("draw").rename(f"{name}apriori"),
        calc_mode(ds.x_prior.dropna(dim="draw").chunk({chunk_dim: chunk_size}), sample_dim="draw").compute().rename(f"{name}apriori_mode"),
        make_quantiles(ds.x_prior.dropna(dim="draw"), sample_dim="draw").rename(f"q{name}apriori"),
    ]
    return output

country_output = xr.merge(calculate_stats(country_traces_merged, "country", "ncountries", 1)
    # [
    # country_traces_merged.xtrace.mean("draw").rename("countryapost"),
    # calc_mode(country_traces_merged.xtrace.chunk({"ncountries": 1}), sample_dim="draw").compute().rename("countryapost_mode"),
    # make_quantiles(country_traces_merged.xtrace, sample_dim="draw").rename("qcountryapost"),
    # country_traces_merged.x_prior.mean("draw").rename("countryapriori"),
    # calc_mode(country_traces_merged.x_prior.dropna(dim="draw").chunk({"ncountries": 1}), sample_dim="draw").compute().rename("countryapriori_mode"),
    # make_quantiles(country_traces_merged.x_prior.dropna(dim="draw"), sample_dim="draw").rename("qcountryapriori"),
# ]
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
country_output
#+end_src

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:              (time: 11, ncountries: 20, probs: 4)
Coordinates:
  ,* time                 (time) datetime64[ns] 2020-06-01 ... 2021-04-01
    country              (ncountries) <U52 'SWITZERLAND' ... 'UNITED KINGDOM'
  ,* probs                (probs) float64 0.025 0.159 0.841 0.975
Dimensions without coordinates: ncountries
Data variables:
    countryapost         (time, ncountries) float64 5.118e+06 ... 1.657e+07
    countryapost_mode    (time, ncountries) float64 4.211e+06 ... 1.576e+07
    qcountryapost        (probs, time, ncountries) float64 1.478e+06 ... 2.28...
    countryapriori       (time, ncountries) float64 5.328e+06 ... 2.798e+07
    countryapriori_mode  (time, ncountries) float64 3.056e+06 ... 2.473e+07
    qcountryapriori      (probs, time, ncountries) float64 9.837e+05 ... 4.27...
#+end_example

* Fluxes

** Get fluxes, traces, basis matrices
#+begin_src jupyter-python :async yes :tangle final1.py
from helpers import get_xr_dummies, sparse_xr_dot

fluxes = [ds.fluxapriori for ds in outs]
basis_mats = [get_xr_dummies(ds.basisfunctions, cat_dim="nparam") for ds in outs]
traces = [trace[["xtrace", "x_prior"]] for trace in all_traces]
#+end_src

#+RESULTS:

** Option 1: concatenate by time, then calculate
#+begin_src jupyter-python :async yes
big_flux = xr.concat([flux.expand_dims({"time": [time]}) for flux, time in zip(fluxes, times)], dim="time")
big_trace = xr.concat([trace.expand_dims({"time": [time]}) for trace, time in zip(traces, times)], dim="time")
big_mat =  xr.concat([mat.expand_dims({"time": [time]}) for mat, time in zip(basis_mats, times)], dim="time")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
country_traces_merged.x_prior.dropna("draw")
#+end_src

#+RESULTS:
#+begin_example
<xarray.DataArray 'x_prior' (time: 11, ncountries: 20, draw: 1000)>
array([[[5.95659523e+06, 1.22424559e+06, 4.14033914e+06, ...,
         3.87380812e+06, 6.88430962e+06, 1.14940891e+07],
        [2.86601844e+06, 2.55800643e+06, 1.66966587e+06, ...,
         1.34725138e+06, 3.53267102e+06, 8.27858279e+05],
        [9.34086308e+05, 2.07387438e+05, 3.54443834e+05, ...,
         5.63844042e+05, 2.91500646e+05, 2.23536646e+06],
        ...,
        [2.74915605e+07, 1.79112287e+07, 1.86589663e+07, ...,
         1.46320878e+07, 5.45173518e+06, 1.74099518e+07],
        [3.46998466e+06, 1.34900990e+06, 2.61891334e+06, ...,
         4.16185254e+06, 1.11864243e+07, 2.67496194e+06],
        [3.10516707e+07, 3.26319017e+07, 3.02851439e+07, ...,
         2.60732882e+07, 2.97760787e+07, 1.98419968e+07]],

       [[2.14210663e+06, 2.71155157e+06, 8.23611006e+06, ...,
         6.60873215e+06, 6.34914998e+06, 3.86433197e+06],
        [3.17699633e+05, 1.22564989e+06, 1.43773538e+06, ...,
         1.22576180e+05, 6.28982911e+05, 1.69525284e+06],
        [1.01475925e+05, 3.04176704e+05, 1.84304614e+05, ...,
         1.34274726e+06, 3.23431346e+05, 3.77945827e+05],
...
        [3.96868155e+06, 2.35125471e+07, 1.85027045e+07, ...,
         7.32773881e+05, 8.64109530e+07, 1.34242285e+07],
        [1.48142526e+06, 2.09597782e+06, 1.80891574e+06, ...,
         2.72474969e+06, 6.88875850e+06, 2.49257388e+05],
        [2.31695268e+07, 2.50544116e+07, 2.07762681e+07, ...,
         3.14615425e+07, 4.69797965e+07, 2.79635901e+07]],

       [[7.97013353e+06, 1.03080007e+07, 2.39029897e+06, ...,
         5.19150931e+06, 6.34158325e+05, 1.43693767e+06],
        [1.99927025e+06, 8.59300318e+05, 6.78194646e+05, ...,
         1.80366596e+06, 1.70939938e+06, 1.34710682e+06],
        [4.00199666e+05, 3.84996209e+05, 2.12722319e+05, ...,
         2.88769416e+06, 2.83659085e+05, 6.04579824e+04],
        ...,
        [3.10184751e+07, 7.95858422e+07, 6.26345017e+05, ...,
         4.45098791e+07, 1.12879634e+07, 9.07126493e+03],
        [6.19784278e+06, 1.83706065e+06, 1.93851538e+06, ...,
         4.29963387e+06, 1.66218218e+06, 2.10044590e+06],
        [3.45226362e+07, 3.40558499e+07, 2.76307991e+07, ...,
         3.84077657e+07, 2.68134008e+07, 2.16398539e+07]]])
Coordinates:
  ,* time     (time) datetime64[ns] 2020-06-01 2020-07-01 ... 2021-04-01
    country  (ncountries) <U52 'SWITZERLAND' 'SWEDEN' ... 'UNITED KINGDOM'
  ,* draw     (draw) int64 0 1 2 3 4 5 6 7 8 ... 992 993 994 995 996 997 998 999
Dimensions without coordinates: ncountries
#+end_example

#+begin_src jupyter-python
flux_stats = calculate_stats(big_trace, "flux", "nparam")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
Cell In[89], line 1
----> 1 flux_stats = calculate_stats(big_trace, "flux", "nparam")

Cell In[84], line 10, in calculate_stats(ds, name, chunk_dim, chunk_size)
      3 def calculate_stats(ds: xr.Dataset, name: str, chunk_dim: str, chunk_size: int = 10) -> xr.Dataset:
      4     output = [
      5         ds.xtrace.mean("draw").rename(f"{name}apost"),
      6         calc_mode(ds.xtrace.chunk({chunk_dim: chunk_size}), sample_dim="draw").compute().rename(f"{name}apost_mode"),
      7         make_quantiles(ds.xtrace, sample_dim="draw").rename(f"q{name}apost"),
      8         ds.x_prior.mean("draw").rename(f"{name}apriori"),
      9         calc_mode(ds.x_prior.dropna(dim="draw").chunk({chunk_dim: chunk_size}), sample_dim="draw").compute().rename(f"{name}apriori_mode"),
---> 10         make_quantiles(ds.x_prior.dropna(dim="draw"), sample_dim="draw").rename(f"q{name}apriori"),
     11     ]
     12     return output

File ~/Documents/acrg/acrg/paris_formatting/helpers.py:148, in make_quantiles(da, probs, sample_dim)
    145     qs = np.moveaxis(qs, 0, -1)
    146     return qs
--> 148 result = xr.apply_ufunc(func, da, probs_da, input_core_dims=[[sample_dim], []])
    149 return result.transpose("probs", ...)

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/xarray/core/computation.py:1266, in apply_ufunc(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)
   1264 # feed DataArray apply_variable_ufunc through apply_dataarray_vfunc
   1265 elif any(isinstance(a, DataArray) for a in args):
-> 1266     return apply_dataarray_vfunc(
   1267         variables_vfunc,
   1268         *args,
   1269         signature=signature,
   1270         join=join,
   1271         exclude_dims=exclude_dims,
   1272         keep_attrs=keep_attrs,
   1273     )
   1274 # feed Variables directly through apply_variable_ufunc
   1275 elif any(isinstance(a, Variable) for a in args):

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/xarray/core/computation.py:314, in apply_dataarray_vfunc(func, signature, join, exclude_dims, keep_attrs, *args)
    309 result_coords, result_indexes = build_output_coords_and_indexes(
    310     args, signature, exclude_dims, combine_attrs=keep_attrs
    311 )
    313 data_vars = [getattr(a, "variable", a) for a in args]
--> 314 result_var = func(*data_vars)
    316 out: tuple[DataArray, ...] | DataArray
    317 if signature.num_outputs > 1:

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/xarray/core/computation.py:821, in apply_variable_ufunc(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)
    816     if vectorize:
    817         func = _vectorize(
    818             func, signature, output_dtypes=output_dtypes, exclude_dims=exclude_dims
    819         )
--> 821 result_data = func(*input_data)
    823 if signature.num_outputs == 1:
    824     result_data = (result_data,)

File ~/Documents/acrg/acrg/paris_formatting/helpers.py:143, in make_quantiles.<locals>.func(a, q)
    142 def func(a, q):
--> 143     qs = np.quantile(a, q, axis=-1)  # apply along input_core_dim = sample_dim
    144     qs = qs[..., 0]  # contracted dimension at axis=-1 is left with length 1, need to remove it
    145     qs = np.moveaxis(qs, 0, -1)

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/numpy/lib/function_base.py:4543, in quantile(a, q, axis, out, overwrite_input, method, keepdims, interpolation)
   4541 if not _quantile_is_valid(q):
   4542     raise ValueError("Quantiles must be in the range [0, 1]")
-> 4543 return _quantile_unchecked(
   4544     a, q, axis, out, overwrite_input, method, keepdims)

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/numpy/lib/function_base.py:4555, in _quantile_unchecked(a, q, axis, out, overwrite_input, method, keepdims)
   4547 def _quantile_unchecked(a,
   4548                         q,
   4549                         axis=None,
   (...)
   4552                         method="linear",
   4553                         keepdims=False):
   4554     """Assumes that q is in [0, 1], and is an ndarray"""
-> 4555     return _ureduce(a,
   4556                     func=_quantile_ureduce_func,
   4557                     q=q,
   4558                     keepdims=keepdims,
   4559                     axis=axis,
   4560                     out=out,
   4561                     overwrite_input=overwrite_input,
   4562                     method=method)

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/numpy/lib/function_base.py:3823, in _ureduce(a, func, keepdims, **kwargs)
   3820             index_out = (0, ) * nd
   3821             kwargs['out'] = out[(Ellipsis, ) + index_out]
-> 3823 r = func(a, **kwargs)
   3825 if out is not None:
   3826     return out

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/numpy/lib/function_base.py:4721, in _quantile_ureduce_func(a, q, axis, out, overwrite_input, method)
   4719     else:
   4720         arr = a.copy()
-> 4721 result = _quantile(arr,
   4722                    quantiles=q,
   4723                    axis=axis,
   4724                    method=method,
   4725                    out=out)
   4726 return result

File ~/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/numpy/lib/function_base.py:4830, in _quantile(arr, quantiles, axis, method, out)
   4823 arr.partition(
   4824     np.unique(np.concatenate(([0, -1],
   4825                               previous_indexes.ravel(),
   4826                               next_indexes.ravel(),
   4827                               ))),
   4828     axis=0)
   4829 if supports_nans:
-> 4830     slices_having_nans = np.isnan(arr[-1, ...])
   4831 else:
   4832     slices_having_nans = None

IndexError: index -1 is out of bounds for axis 0 with size 0
#+end_example
:END:

...this is problematic because there are varying numbers of basis functions for each month, causing some combinations of ~(time, nparam)~ to have NaNs.
Dropping NaNs along the "draw" dimension then drops all draws...

** Option 2: calculate, then concatenate by time

#+begin_src jupyter-python
import dask
import dask.bag as db

b = db.from_sequence([trace.expand_dims({"time": [time]}) for trace, time in zip(traces, times)], npartitions=4)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :async yes
result = b.map(lambda x: xr.merge(calculate_stats(x, "flux", "nparam"))).compute()
#+end_src

#+RESULTS:

#+begin_src jupyter-python
flux_stats = xr.concat(result, dim="time").sortby("time")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
x_to_domain = big_flux * big_mat
#+end_src

#+RESULTS:

#+begin_src jupyter-python :async yes
x_to_domain.shape[:-1]
#+end_src

#+RESULTS:
| 11 | 293 | 391 |

#+begin_src jupyter-python :async yes
# %%debug --breakpoint /home/brendan/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/xarray/core/alignment.py:242
flux_outputs = sparse_xr_dot(x_to_domain, flux_stats.fillna(0.0), broadcast_dims=["time", "probs"])
#+end_src

#+RESULTS:


#+begin_src jupyter-python
print(np.sum(np.isnan(flux_outputs.fluxapost)), np.sum(~np.isnan(flux_outputs.fluxapost)), 11 * 293 * 391)
#+end_src

#+RESULTS:
: <xarray.DataArray 'fluxapost' ()>
: array(229126) <xarray.DataArray 'fluxapost' ()>
: array(1031067) 1260193

** Option 3: concatenate by time at very end (no dask)

Concatenating by time creates NaNs because of unequal number of basis regions...

#+begin_src jupyter-python :async yes :tangle final1.py
stats = [xr.merge(calculate_stats(trace, "flux", "nparam")) for trace in traces]
#+end_src

#+RESULTS:

#+begin_src jupyter-python :async yes :tangle final1.py
flux_stats = [sparse_xr_dot((flux * mat), stats_ds) for flux, mat, stats_ds in zip(fluxes, basis_mats, stats)]
#+end_src

#+RESULTS:
#+RESULTS:


#+begin_src jupyter-python :async yes :tangle final1.py
flux_stats_plus_time = [fs.expand_dims({"time": [time]}) for fs, time in zip(flux_stats, times)]
flux_all_times = xr.concat(flux_stats_plus_time, dim="time")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
flux_all_times
#+end_src

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:           (time: 11, lat: 293, lon: 391, probs: 4)
Coordinates:
  ,* time              (time) datetime64[ns] 2020-06-01 2020-07-01 ... 2021-04-01
  ,* lat               (lat) float32 10.73 10.96 11.2 11.43 ... 78.59 78.82 79.06
  ,* lon               (lon) float32 -97.9 -97.55 -97.2 ... 38.68 39.03 39.38
  ,* probs             (probs) float64 0.025 0.159 0.841 0.975
Data variables:
    fluxapost         (time, lat, lon) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapost_mode    (time, lat, lon) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapost        (time, lat, lon, probs) float64 0.0 0.0 0.0 ... 0.0 0.0
    fluxapriori       (time, lat, lon) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapriori_mode  (time, lat, lon) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapriori      (time, lat, lon, probs) float64 0.0 0.0 0.0 ... 0.0 0.0
#+end_example

#+begin_src jupyter-python
print(np.sum(np.isnan(flux_all_times.fluxapost)), np.sum(~np.isnan(flux_all_times.fluxapost)), 11 * 293 * 391)
#+end_src

#+RESULTS:
: <xarray.DataArray 'fluxapost' ()>
: array(0) <xarray.DataArray 'fluxapost' ()>
: array(1260193) 1260193


* Combined country totals and fluxes
** Attributes
#+begin_src jupyter-python :tangle final1.py
from attribute_parsers import get_data_var_attrs, write_data_var_attrs, make_global_attrs

flux_attrs = get_data_var_attrs("netcdf_template_emissions_bm_edits.txt")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
for k, v in flux_attrs.items():
    print(k, v)
#+end_src

#+RESULTS:
#+begin_example
time {'long_name': 'time', 'units': 'seconds since 1970-01-01 00:00:00', 'calendar': 'proleptic_gregorian'}
quantile {'units': '-', 'long_name': 'quantile'}
lon {'units': 'degree_east', 'long_name': 'longitude_of_grid_cell_centre'}
lat {'units': 'degree_north', 'long_name': 'latitude_of_grid_cell_centre'}
country {'long_name': 'country name'}
fluxapriori {'units': 'mol/m2/s', 'long_name': 'apriori_flux'}
qfluxapriori {'units': 'mol/m2/s', 'long_name': 'quantiles_of_apriori_flux', 'comment': 'shape of pdf'}
fluxapost {'units': 'mol/m2/s', 'long_name': 'aposteriori_flux'}
qfluxapost {'units': 'mol/m2/s', 'long_name': 'quantiles_of_aposteriori_flux'}
countryapriori {'units': 'kg', 'long_name': 'apriori_flux_per_country'}
qcountryapriori {'units': 'kg', 'long_name': 'quantiles_of_apriori_flux_per_country'}
countryapost {'units': 'kg', 'long_name': 'aposteriori_flux_per_country'}
qcountryapost {'units': 'kg', 'long_name': 'quantiles_of_aposteriori_flux_per_country'}
covcountryapost {'units': 'kg2', 'long_name': 'spatial_covariance_of_aposteriori_flux_per_country'}
#+end_example

** Time conversion
#+begin_src jupyter-python :tangle final1.py
from helpers import convert_time_to_unix_epoch
#+end_src

#+RESULTS:

#+begin_src jupyter-python
res = convert_time_to_unix_epoch(flux_all_times.fluxapost)
res
#+end_src

#+RESULTS:
#+begin_example
<xarray.DataArray 'fluxapost' (time: 11, lat: 293, lon: 391)>
array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
...
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
Coordinates:
  ,* lat      (lat) float32 10.73 10.96 11.2 11.43 ... 78.36 78.59 78.82 79.06
  ,* lon      (lon) float32 -97.9 -97.55 -97.2 -96.84 ... 38.32 38.68 39.03 39.38
  ,* time     (time) int64 1590969600 1593561600 ... 1614556800 1617235200
#+end_example

#+begin_src jupyter-python
from helpers import convert_unix_epoch_to_time

convert_unix_epoch_to_time(res)
#+end_src

#+RESULTS:
#+begin_example
<xarray.DataArray 'fluxapost' (time: 11, lat: 293, lon: 391)>
array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
...
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
Coordinates:
  ,* lat      (lat) float32 10.73 10.96 11.2 11.43 ... 78.36 78.59 78.82 79.06
  ,* lon      (lon) float32 -97.9 -97.55 -97.2 -96.84 ... 38.32 38.68 39.03 39.38
  ,* time     (time) datetime64[ns] 2020-06-01 2020-07-01 ... 2021-04-01
#+end_example

** Combining flux and country totals

#+begin_src jupyter-python
country_output.swap_dims(ncountries="country").rename_vars(probs="quantile").swap_dims(probs="quantile").dims
#+end_src

#+RESULTS:
: Frozen({'time': 11, 'country': 20, 'quantile': 4})

#+begin_src jupyter-python
flux_all_times.rename_vars(probs="quantile").swap_dims(probs="quantile").dims
#+end_src

#+RESULTS:
: Frozen({'time': 11, 'lat': 293, 'lon': 391, 'quantile': 4})

#+begin_src jupyter-python :tangle final1.py
emissions1 = xr.merge([flux_all_times, country_output.swap_dims(ncountries="country")])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
emissions1.dims
#+end_src

#+RESULTS:
: Frozen({'time': 11, 'lat': 293, 'lon': 391, 'probs': 4, 'country': 20})

#+begin_src jupyter-python :tangle final1.py
emissions2 = convert_time_to_unix_epoch(emissions1)
emissions3 = emissions2.rename_vars(probs="quantile").swap_dims(probs="quantile")
#+end_src

#+RESULTS:

** Merging issues...

#+begin_src jupyter-python
ds1 = country_output[["countryapost", "qcountryapost"]].isel(ncountries=0, drop=True)
ds1
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:        (time: 11, probs: 4)
: Coordinates:
:   * time           (time) datetime64[ns] 2020-06-01 2020-07-01 ... 2021-04-01
:   * probs          (probs) float64 0.025 0.159 0.841 0.975
: Data variables:
:     countryapost   (time) float64 5.118e+06 5.146e+06 ... 1.201e+07 1.037e+07
:     qcountryapost  (probs, time) float64 1.478e+06 1.068e+06 ... 1.663e+07

#+begin_src jupyter-python
ds2 = flux_all_times[["fluxapost", "qfluxapost"]].isel(lat=0, lon=0, drop=True)
ds2
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:     (time: 11, probs: 4)
: Coordinates:
:   * time        (time) datetime64[ns] 2020-06-01 2020-07-01 ... 2021-04-01
:   * probs       (probs) float64 0.025 0.159 0.841 0.975
: Data variables:
:     fluxapost   (time) float64 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
:     qfluxapost  (time, probs) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0

#+begin_src jupyter-python
print(ds1.rename_vars(probs="quantile").swap_dims(probs="quantile").dims)
print(ds2.rename_vars(probs="quantile").swap_dims(probs="quantile").dims)
#+end_src

#+RESULTS:
: Frozen({'time': 11, 'quantile': 4})
: Frozen({'time': 11, 'quantile': 4})

#+begin_src jupyter-python
print(xr.merge([ds1.rename_vars(probs="quantile").swap_dims(probs="quantile"), ds2.rename_vars(probs="quantile").swap_dims(probs="quantile")]).dims)
#+end_src

#+RESULTS:
: Frozen({'time': 11, 'quantile': 4, 'probs': 4})

#+begin_src jupyter-python
ds1b = ds1.rename_vars(probs="quantile").swap_dims(probs="quantile")
ds2b = ds2.rename_vars(probs="quantile").swap_dims(probs="quantile")
print(ds1b.dims, ds2b.dims)
print(xr.merge([ds1b, ds2b]).dims)
#+end_src

*** Isolated example
#+RESULTS:
: Frozen({'time': 11, 'quantile': 4}) Frozen({'time': 11, 'quantile': 4})
: Frozen({'time': 11, 'quantile': 4, 'probs': 4})

#+begin_src jupyter-python
A = np.arange(4).reshape((2, 2))
B = np.arange(4).reshape((2, 2)) + 4
ds1 = xr.Dataset({"A": (["x", "y"], A), "B": (["x", "y"], B)}, coords={"x": ("x", [1, 2]), "y": ("y", [1, 2])})
ds2 = xr.Dataset({"C": (["x", "y"], A), "D": (["x", "y"], B)}, coords={"x": ("x", [1, 2]), "y": ("y", [1, 2])})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
ds1_swap = ds1.rename_vars(y="z").swap_dims(y="z")
ds2_swap = ds2.rename_vars(y="z").swap_dims(y="z")
print(ds1_swap.dims, ds2_swap.dims)
print(ds1_swap.indexes, ds2_swap.indexes)
#+end_src

#+RESULTS:
: Frozen({'x': 2, 'z': 2}) Frozen({'x': 2, 'z': 2})
: Indexes:
:     x        Int64Index([1, 2], dtype='int64', name='x')
:     z        Int64Index([1, 2], dtype='int64', name='z') Indexes:
:     x        Int64Index([1, 2], dtype='int64', name='x')
:     z        Int64Index([1, 2], dtype='int64', name='z')

#+begin_src jupyter-python
ds1_swap
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:  (x: 2, z: 2)
: Coordinates:
:   * x        (x) int64 1 2
:   * z        (z) int64 1 2
: Data variables:
:     A        (x, z) int64 0 1 2 3
:     B        (x, z) int64 4 5 6 7

#+begin_src jupyter-python
ds1.swap_dims(y="z").rename_vars(y="z")
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:  (x: 2, z: 2)
: Coordinates:
:   * x        (x) int64 1 2
:     z        (z) int64 1 2
: Data variables:
:     A        (x, z) int64 0 1 2 3
:     B        (x, z) int64 4 5 6 7

#+begin_src jupyter-python
A = np.arange(4).reshape((2, 2))
B = np.arange(4).reshape((2, 2)) + 4
ds1 = xr.Dataset({"A": (["x", "y"], A), "B": (["x", "y"], B)}, coords={"x": ("x", [1, 2]), "y": ("y", [1, 2])})
ds2 = xr.Dataset({"C": (["x", "y"], A), "D": (["x", "y"], B)}, coords={"x": ("x", [1, 2]), "y": ("y", [1, 2])})

ds1_swap = ds1.rename_vars(y="z").swap_dims(y="z")
ds2_swap = ds2.rename_vars(y="z").swap_dims(y="z")

assert xr.merge([ds1_swap, ds2_swap]).dims == ds1_swap.dims
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AssertionError                            Traceback (most recent call last)
: Cell In[317], line 9
:       6 ds1_swap = ds1.rename_vars(y="z").swap_dims(y="z")
:       7 ds2_swap = ds2.rename_vars(y="z").swap_dims(y="z")
: ----> 9 assert xr.merge([ds1_swap, ds2_swap]).dims == ds1_swap.dims
:
: AssertionError:
:END:

#+begin_src jupyter-python
ds12 = xr.merge([ds1, ds2]).rename_vars(y="z").swap_dims(y="z")
ds12
#+end_src

#+RESULTS:
: <xarray.Dataset>
: Dimensions:  (x: 2, z: 2)
: Coordinates:
:   * x        (x) int64 1 2
:   * z        (z) int64 1 2
: Data variables:
:     A        (x, z) int64 0 1 2 3
:     B        (x, z) int64 4 5 6 7
:     C        (x, z) int64 0 1 2 3
:     D        (x, z) int64 4 5 6 7

#+begin_src jupyter-python
ds3 = xr.Dataset({"E": (["x", "z"], A), "F": (["x", "z"], B)}, coords={"x": ("x", [1, 2]), "z": ("z", [1, 2])})

ds123 = xr.merge([ds12, ds3])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
assert ds123.dims == ds3.dims
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AssertionError                            Traceback (most recent call last)
: Cell In[328], line 1
: ----> 1 assert ds123.dims == ds3.dims
:
: AssertionError:
:END:

#+begin_src jupyter-python
assert ds12.dims == ds3.dims
assert ds123.dims == xr.merge([ds1_swap, ds2_swap]).dims
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from xarray.core.utils import Frozen
assert ds1.dims == Frozen({"x": 2, "y": 2})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
assert ds1.dims == Frozen({"x": 2, "y": 2})
assert ds2.dims == Frozen({"x": 2, "y": 2})

assert ds1_swap.dims == Frozen({"x": 2, "z": 2})
assert ds2_swap.dims == Frozen({"x": 2, "z": 2})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
assert xr.merge([ds1_swap, ds2_swap]).dims == Frozen({"x": 2, "z": 2, "y": 2})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
assert ds12.dims == Frozen({"x": 2, "z": 2})
assert ds3.dims == Frozen({"x": 2, "z": 2})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
assert ds123.dims == Frozen({"x": 2, "z": 2, "y": 2})
assert ds123.dims != Frozen({"x": 2, "z": 2})
#+end_src

#+RESULTS:

#+begin_src jupyter-python
xr.show_versions()
#+end_src

#+RESULTS:
#+begin_example

INSTALLED VERSIONS
------------------
commit: None
python: 3.10.13 (main, Nov 10 2023, 15:02:19) [GCC 11.4.0]
python-bits: 64
OS: Linux
OS-release: 6.5.0-14-generic
machine: x86_64
processor: x86_64
byteorder: little
LC_ALL: None
LANG: en_GB.UTF-8
LOCALE: ('en_GB', 'UTF-8')
libhdf5: 1.12.2
libnetcdf: 4.9.3-development

xarray: 2023.11.0
pandas: 1.5.3
numpy: 1.26.2
scipy: 1.11.4
netCDF4: 1.6.5
pydap: None
h5netcdf: 1.3.0
h5py: 3.10.0
Nio: None
zarr: None
cftime: 1.6.3
nc_time_axis: 1.4.1
iris: None
bottleneck: None
dask: 2023.12.0
distributed: None
matplotlib: 3.8.2
cartopy: 0.22.0
seaborn: 0.13.0
numbagg: None
fsspec: 2023.12.1
cupy: None
pint: None
sparse: 0.15.1
flox: None
numpy_groupies: None
setuptools: 69.0.2
pip: 23.3.1
conda: None
pytest: 7.4.3
mypy: None
IPython: 8.18.1
sphinx: None
/home/brendan/Documents/inversions/.pymc_venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
#+end_example

#+begin_src jupyter-python
ds12_as = ds12.assign_coords(x=(ds12.x + 1))
assert ds12_as.sizes == Frozen({"x": 2, "z": 2, "y": 2})
#+end_src

#+RESULTS:

** Updating attributes

#+begin_src jupyter-python :tangle final1.py
from attribute_parsers import add_variable_attrs

emissions4 = add_variable_attrs(emissions3, flux_attrs)
#+end_src

#+RESULTS:


#+begin_src jupyter-python :tangle final1.py
emissions4.attrs = make_global_attrs("flux")
#+end_src

#+RESULTS:

#+begin_src jupyter-python
emissions4
#+end_src

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:              (time: 11, lat: 293, lon: 391, quantile: 4, country: 20)
Coordinates:
  ,* lat                  (lat) float32 10.73 10.96 11.2 ... 78.59 78.82 79.06
  ,* lon                  (lon) float32 -97.9 -97.55 -97.2 ... 38.68 39.03 39.38
  ,* quantile             (quantile) float64 0.025 0.159 0.841 0.975
  ,* country              (country) <U52 'SWITZERLAND' ... 'UNITED KINGDOM'
  ,* time                 (time) int64 1590969600 1593561600 ... 1617235200
Data variables:
    fluxapost            (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapost_mode       (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapost           (time, lat, lon, quantile) float64 0.0 0.0 ... 0.0 0.0
    fluxapriori          (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapriori_mode     (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapriori         (time, lat, lon, quantile) float64 0.0 0.0 ... 0.0 0.0
    countryapost         (time, country) float64 5.118e+06 ... 1.657e+07
    countryapost_mode    (time, country) float64 4.211e+06 ... 1.576e+07
    qcountryapost        (quantile, time, country) float64 1.478e+06 ... 2.28...
    countryapriori       (time, country) float64 5.328e+06 ... 2.798e+07
    countryapriori_mode  (time, country) float64 3.056e+06 ... 2.473e+07
    qcountryapriori      (quantile, time, country) float64 9.837e+05 ... 4.27...
Attributes: (12/13)
    title:                         Flux estimates: spatially-resolved and by ...
    author:                        OpenGHG
    source:                        processed NAME(8.0) model output
    transport_model:               NAME
    transport_model_version:       NAME III (version 8.0)
    met_model:                     UKV
    ...                            ...
    domain:                        EUROPE
    inversion_method:              RHIME
    apriori_description:           EDGAR 8.0
    publication_acknowledgements:  Please acknowledge ACRG, University of Bri...
    history:
    comment:
#+end_example

** Replacing country names with codes

#+begin_src jupyter-python
import json

with open("iso3166.json", "r") as f:
    iso3166 = json.load(f)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
country_codes = {}
for c in paris_countries + paris_countries_ukmo:
    found = False
    for k, v in iso3166.items():
        names = [v["iso_long_name"].lower()] + [name.lower() for name in v["unofficial_names"]]
        if any(c.lower() in name for name in names):
            country_codes[c] = k
            found = True
            continue
    if not found:
        country_codes[c] = c
#+end_src

#+RESULTS:

#+begin_src jupyter-python
for k, v in country_codes.items():
    print(k, v)
#+end_src

#+RESULTS:
#+begin_example
BELGIUM BE
SWITZERLAND CH
AUSTRIA AT
ITALY IT
NETHERLANDS NL
CZECHIA CZ
POLAND PL
HUNGARY HU
SLOVAKIA SK
SWEDEN SE
FINLAND FI
BENELUX BENELUX
RestEU RestEU
SpaPor SpaPor
IRELAND IE
UNITED KINGDOM GB
FRANCE TF
GERMANY DE
DENMARK DK
NORWAY NO
#+end_example

#+begin_src jupyter-python
from typing import Any, Optional
def get_country_code(x: str, iso3166: Optional[dict[str, dict[str, Any]]] = None) -> str:
    if iso3166 is None:
        import json

        with open("iso3166.json", "r") as f:
            iso3166 = json.load(f)

    for k, v in iso3166.items():
        names = [v["iso_long_name"].lower()] + [name.lower() for name in v["unofficial_names"]]
        if any(x.lower() in name for name in names):
            return k

    return x
#+end_src

#+RESULTS:

#+begin_src jupyter-python
emissions4.assign_coords(country=list(map(lambda x: get_country_code(x, iso3166), map(str, emissions4.country.values))))
#+end_src

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:              (time: 11, lat: 293, lon: 391, quantile: 4, probs: 4,
                          country: 20)
Coordinates:
  ,* lat                  (lat) float32 10.73 10.96 11.2 ... 78.59 78.82 79.06
  ,* lon                  (lon) float32 -97.9 -97.55 -97.2 ... 38.68 39.03 39.38
  ,* quantile             (probs) float64 0.025 0.159 0.841 0.975
  ,* time                 (time) int64 1590969600 1593561600 ... 1617235200
  ,* country              (country) <U7 'CH' 'SE' 'SK' ... 'SpaPor' 'NO' 'GB'
Dimensions without coordinates: probs
Data variables:
    fluxapost            (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapost_mode       (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapost           (time, lat, lon, quantile) float64 0.0 0.0 ... 0.0 0.0
    fluxapriori          (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    fluxapriori_mode     (time, lat, lon) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0
    qfluxapriori         (time, lat, lon, quantile) float64 0.0 0.0 ... 0.0 0.0
    countryapost         (time, country) float64 5.118e+06 ... 1.657e+07
    countryapost_mode    (time, country) float64 4.211e+06 ... 1.576e+07
    qcountryapost        (quantile, time, country) float64 1.478e+06 ... 2.28...
    countryapriori       (time, country) float64 5.328e+06 ... 2.798e+07
    countryapriori_mode  (time, country) float64 3.056e+06 ... 2.473e+07
    qcountryapriori      (quantile, time, country) float64 9.837e+05 ... 4.27...
Attributes: (12/13)
    title:                         Flux estimates: spatially-resolved and by ...
    author:                        OpenGHG
    source:                        processed NAME(8.0) model output
    transport_model:               NAME
    transport_model_version:       NAME III (version 8.0)
    met_model:                     UKV
    ...                            ...
    domain:                        EUROPE
    inversion_method:              RHIME
    apriori_description:           EDGAR 8.0
    publication_acknowledgements:  Please acknowledge ACRG, University of Bri...
    history:
    comment:
#+end_example

* Refining sampling code

#+begin_src jupyter-python
from pymc.distributions import continuous
continuous_dists = continuous.__all__
#+end_src

#+RESULTS:

#+begin_src jupyter-python
cd_dict = {cd.lower(): cd for cd in continuous_dists}
#+end_src

#+RESULTS:

#+begin_src jupyter-python
for k, v in cd_dict.items():
    print(k, getattr(continuous, v))
#+end_src

#+RESULTS:
#+begin_example
uniform <class 'pymc.distributions.continuous.Uniform'>
flat <class 'pymc.distributions.continuous.Flat'>
halfflat <class 'pymc.distributions.continuous.HalfFlat'>
normal <class 'pymc.distributions.continuous.Normal'>
truncatednormal <class 'pymc.distributions.continuous.TruncatedNormal'>
beta <class 'pymc.distributions.continuous.Beta'>
kumaraswamy <class 'pymc.distributions.continuous.Kumaraswamy'>
exponential <class 'pymc.distributions.continuous.Exponential'>
laplace <class 'pymc.distributions.continuous.Laplace'>
studentt <class 'pymc.distributions.continuous.StudentT'>
cauchy <class 'pymc.distributions.continuous.Cauchy'>
halfcauchy <class 'pymc.distributions.continuous.HalfCauchy'>
gamma <class 'pymc.distributions.continuous.Gamma'>
weibull <class 'pymc.distributions.continuous.Weibull'>
halfstudentt <class 'pymc.distributions.continuous.HalfStudentT'>
lognormal <class 'pymc.distributions.continuous.LogNormal'>
chisquared <class 'pymc.distributions.continuous.ChiSquared'>
halfnormal <class 'pymc.distributions.continuous.HalfNormal'>
wald <class 'pymc.distributions.continuous.Wald'>
pareto <class 'pymc.distributions.continuous.Pareto'>
inversegamma <class 'pymc.distributions.continuous.InverseGamma'>
exgaussian <class 'pymc.distributions.continuous.ExGaussian'>
vonmises <class 'pymc.distributions.continuous.VonMises'>
skewnormal <class 'pymc.distributions.continuous.SkewNormal'>
triangular <class 'pymc.distributions.continuous.Triangular'>
gumbel <class 'pymc.distributions.continuous.Gumbel'>
logistic <class 'pymc.distributions.continuous.Logistic'>
logitnormal <class 'pymc.distributions.continuous.LogitNormal'>
interpolated <class 'pymc.distributions.continuous.Interpolated'>
rice <class 'pymc.distributions.continuous.Rice'>
moyal <class 'pymc.distributions.continuous.Moyal'>
asymmetriclaplace <class 'pymc.distributions.continuous.AsymmetricLaplace'>
polyagamma <class 'pymc.distributions.continuous.PolyaGamma'>
#+end_example

#+begin_src jupyter-python
function_dict = {
        "uniform": pm.Uniform,
        "flat": pm.Flat,
        "halfflat": pm.HalfFlat,
        "normal": pm.Normal,
        "truncatednormal": pm.TruncatedNormal,
        "halfnormal": pm.HalfNormal,
        "skewnormal": pm.SkewNormal,
        "beta": pm.Beta,
        "kumaraswamy": pm.Kumaraswamy,
        "exponential": pm.Exponential,
        "laplace": pm.Laplace,
        "studentt": pm.StudentT,
        "halfstudentt": pm.HalfStudentT,
        "cauchy": pm.Cauchy,
        "halfcauchy": pm.HalfCauchy,
        "gamma": pm.Gamma,
        "inversegamma": pm.InverseGamma,
        "weibull": pm.Weibull,
        "lognormal": pm.Lognormal,
        "chisquared": pm.ChiSquared,
        "wald": pm.Wald,
        "pareto": pm.Pareto,
        "exgaussian": pm.ExGaussian,
        "vonmises": pm.VonMises,
        "triangular": pm.Triangular,
        "gumbel": pm.Gumbel,
        "rice": pm.Rice,
        "logistic": pm.Logistic,
        "logitnormal": pm.LogitNormal,
        "interpolated": pm.Interpolated,
    }

print(len(function_dict), len(cd_dict))
assert set(function_dict.keys()) <= set(cd_dict.keys())
#+end_src

#+RESULTS:
: 30 33
