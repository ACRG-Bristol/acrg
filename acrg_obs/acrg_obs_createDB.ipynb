{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from acrg.acrg_config.paths import paths\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories to exclude from database\n",
    "exclude = [\"GOSAT\", \"unknown\"]\n",
    "\n",
    "network = []\n",
    "instrument = []\n",
    "site_code = []\n",
    "start_date = []\n",
    "end_date = []\n",
    "species = []\n",
    "height = []\n",
    "calibration_scale = []\n",
    "filename = []\n",
    "\n",
    "# Find sub-directories in obs folder\n",
    "for d in paths.obs.glob(\"*\"):\n",
    "    if d.is_dir():\n",
    "        if d.name not in exclude:\n",
    "            \n",
    "            # Find netcdf files\n",
    "            files = d.glob(\"*.nc\")\n",
    "            for f in files:\n",
    "                \n",
    "                # TODO: Some files are empty. Figure out why!\n",
    "                if os.stat(f).st_size != 0:\n",
    "                    \n",
    "                    #TODO: add try/except to see if files open with xarray \n",
    "                    \n",
    "                    f_parts = f.name.split(\"_\")\n",
    "\n",
    "                    network.append(f_parts[0].split(\"-\")[0])\n",
    "                    instrument.append(f_parts[0].split(\"-\")[1])\n",
    "\n",
    "                    site_code.append(f_parts[1])\n",
    "\n",
    "                    extras = f_parts[3].split(\"-\")\n",
    "                    species.append(extras[0])\n",
    "                    if len(extras) == 3:\n",
    "                        height.append(extras[1])\n",
    "                    else:\n",
    "                        height.append(\"%\")\n",
    "\n",
    "                    with xr.open_dataset(f) as ds:\n",
    "                        if \"Calibration_scale\" in ds.attrs.keys():\n",
    "                            calibration_scale.append(ds.attrs[\"Calibration_scale\"])\n",
    "                        else:\n",
    "                            calibration_scale.append(None)\n",
    "                        start_date.append(pd.Timestamp(ds[\"time\"].values[0]).to_pydatetime())\n",
    "                        end_date.append(pd.Timestamp(ds[\"time\"].values[-1]).to_pydatetime())\n",
    "                            \n",
    "                    filename.append(str(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = list(zip(filename, network, instrument, site_code, species, height, calibration_scale, start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write database\n",
    "\n",
    "conn = sqlite3.connect(paths.obs / \"obs.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''DROP TABLE IF EXISTS files\n",
    "          ''')\n",
    "c.execute('''CREATE TABLE files\n",
    "             (filename text, network text, instrument text, site text, species text, height text, scale text, startDate timestamp, endDate timestamp)''')\n",
    "\n",
    "c.executemany('INSERT INTO files VALUES (?,?,?,?,?,?,?,?,?)', file_info)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2017-03-17 16:55:22.500000',)\n",
      "('2019-03-06 13:23:30',)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "conn = sqlite3.connect(paths.obs / \"obs.db\")\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "species_site_height = (\"N2O\", \"bsd\", \"248m\")\n",
    "for row in c.execute('''SELECT startDate FROM files WHERE \n",
    "                        species=? COLLATE NOCASE AND\n",
    "                        site=? COLLATE NOCASE AND\n",
    "                        height=?\n",
    "                        ''', species_site_height):\n",
    "    print(row)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pandas\n",
    "\n",
    "conn = sqlite3.connect(paths.obs / \"obs.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM files\", conn, parse_dates=[\"startDate\", \"endDate\"])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
