#!/bin/ksh
# ******************************************************************************
#
# Project: Template files and scripts for research users on NAME-JASMIN
#
# File:    Sample script for NAME back runs from one site structured by day
#
# Author:  Andrew Jones, Atmospheric Dispersion, UK Met Office
#
# Date:    25/09/2014
#
# ******************************************************************************

# Summary of set up for back runs:
#
#  A separate NAME back run is performed for each calendar day between
#  prescribed start and end dates (loop over dates)
#
#  - each back run calculates an N-day air history for the air arriving at a
#    single receptor over each M-hour time window during that 24-hour period
#
#  - each back run uses GLOBAL NWP analysis data (with update-on-demand)
#
#
# Update History:
#
# 08/10/2013 - original version of script supplied to Ag Stephens at BADC
#
# 26/11/2013 - version 2 includes automatic specification of the GLOBAL NWP data
#              to use based on the dates for each NAME simulation (currently the
#              start date and end date of each NAME run must be covered by the
#              same 'Mk' data, although this restriction might be relaxed later)
#
# 25/09/2014 - updated to include 'Mk8' GLOBAL UM option to be used for dates
#              from 15/07/2014 onwards.
#
# 20/11/2015 - updated to NAME v6.5 and to include support for 'Mk9' GLOBAL UM
#              option to be used for dates from 25/08/2015 onwards.
#
# 08/05/2017 - updated to add GLOUM6 met data ('Mk3') prior to 01/01/2009
#

echo "Script $0 starting at" `date`

# Set system variables

. /etc/profile

ulimit -s unlimited

GWS=/home
USER=ag12733

# ------------------------------------------------------------------------------
#
#  **  Functions  **
#
# ------------------------------------------------------------------------------

# Gets the Mk (version number) of Global met data appropriate to a given date

get_Mk_Global(){

  # Input date as seconds from Jan 1, 1970
  
  if [[ ${GlobalMetDate} -lt 1136073600 ]] ; then
    
    let GlobalMetMk=0
    echo "ERROR in get_Mk_Global: date is before the earliest available Global met data"
    exit 1
    
  elif [[ ${GlobalMetDate} -lt 1230768000 ]] ; then
    
    let GlobalMetMk=3
    
  elif [[ ${GlobalMetDate} -lt 1257811200 ]] ; then
    
    let GlobalMetMk=4
    
  elif [[ ${GlobalMetDate} -lt 1268092800 ]] ; then
    
    let GlobalMetMk=5
    
  elif [[ ${GlobalMetDate} -lt 1367280000 ]] ; then
    
    let GlobalMetMk=6
    
  elif [[ ${GlobalMetDate} -lt 1405382400 ]] ; then
    
    let GlobalMetMk=7
    
  elif [[ ${GlobalMetDate} -lt 1440460800 ]] ; then
    
    let GlobalMetMk=8
    
  else
    
    let GlobalMetMk=9
    
  fi

}

# ------------------------------------------------------------------------------
#
#  **  NWP specifications - these are fixed and should not be changed **
#
# ------------------------------------------------------------------------------

# Met Type             |   Dates
# -------------------------------------------------
#
# GLOUM6               |  01/01/2006 --> 31/12/2008
#
# GLOUM6pp             |  01/01/2009 --> 09/11/2009
#
# UMG_Mk5              |  10/11/2009 --> 08/03/2010
#
# UMG_Mk6              |  09/03/2010 --> 29/04/2013
#
# UMG_Mk7              |  30/04/2013 --> 14/07/2014
#
# UMG_Mk8              |  15/07/2014 --> 25/08/2015
#
# UMG_Mk9              |  25/08/2015 --> ---
#

set -A MetMk             0       1       2       3                  4                    5                           6                             7                             8                             9                           
set -A MetType           'null'  'null'  'null'  'GLOUM6'           'GLOUM6pp'           'UMG_Mk5'                   'UMG_Mk6PT'                   'UMG_Mk7PT'                   'UMG_Mk8PT'                   'UMG_Mk9PT'
set -A MetDefnFileName   'null'  'null'  'null'  'MetDefnUM6G.txt'  'MetDefnUM6Gpp.txt'  'MetDefnUMG_Mk5_L52pp.txt'  'MetDefnUMG_Mk6_L59PTpp.txt'  'MetDefnUMG_Mk7_L59PTpp.txt'  'MetDefnUMG_Mk8_L59PTpp.txt'  'MetDefnUMG_Mk9_L59PTpp.txt'
set -A MetDeclnFileName  'null'  'null'  'null'  'Use_UM6G.txt'     'Use_UM6Gpp.txt'     'Use_UMG_Mk5_L52pp.txt'     'Use_UMG_Mk6_L59PTpp.txt'     'Use_UMG_Mk7_L59PTpp.txt'     'Use_UMG_Mk8_L59PTpp.txt'     'Use_UMG_Mk9_L59PTpp.txt'
set -A MetPrefix         'null'  'null'  'null'  'HP'               'HP'                 'MO'                        'MO'                          'MO'                          'MO'                          'MO'
set -A MetSuffix         'null'  'null'  'null'  'GLOUM6'           'GLOUM6.pp'          'UMG_Mk5_L52.pp'            'UMG_Mk6_L59PT*.pp'           'UMG_Mk7_[IM]_L59PT*.pp'      'UMG_Mk8_[IM]_L59PT*.pp'      'UMG_Mk9_[IM]_L59PT*.pp'
set -A ArchiveMetDir     'null'  'null'  'null'  'Global/GLOUM6'    'Global/GLOUM6pp'    'Global/UMG_Mk5'            'Global/UMG_Mk6PT'            'Global/UMG_Mk7PT'            'Global/UMG_Mk8PT'            'Global/UMG_Mk9PT'



# ------------------------------------------------------------------------------
#
#  **  Script parameters and arguments  **
#
# ------------------------------------------------------------------------------

# Correct usage string (for display in error messages)

Usage="Usage: $0  [-h]  start_date  end_date"

# Get optional parameters

while getopts :h name ; do
  case ${name} in
    h) # option: help
      echo '---------------------------------------------------'
      echo ${Usage}
      echo '---------------------------------------------------'
      echo ''
      echo 'Required parameters:'
      echo '   start_date is the start date for back runs'
      echo '   end_date   is the end date for back runs'
      echo ''
      echo ' with date format "%Y-%M-%D", e.g. 2012-01-31'
      echo ''
      echo 'Optional parameters:'
      echo '  -h  displays this help page'
      echo ''
      echo '---------------------------------------------------'
      exit 0
      ;;
    :) # expected argument is missing
      echo 'Error: missing argument for option -'${OPTARG}
      echo ${Usage}
      exit 1
      ;;
    ?) # illegal option
      echo 'Error: illegal option -'${OPTARG}
      echo ${Usage}
      exit 1
      ;;
    *) # unexpected error
      echo 'Error: unexpected problem reading optional parameters'
      echo ${Usage}
      exit 1
      ;;
  esac
done

shift $((${OPTIND}-1))
 
#  Get input arguments: start date and end date

if [[ $# -eq 2 ]] ; then
  
  start_date=$1
  end_date=$2
  
else
  
  echo "Error in script $0: two date arguments (%Y-%M-%D) are required for start and end dates"
  echo ${Usage}
  exit 1
  
fi

# Now check input dates are well-specified with an end date after the start date

start_seconds=`date -u -d "${start_date} 00:00 UTC" +'%s'`

if [[ $? != 0 || ${start_seconds}'X' == 'X' ]] ; then
  
  echo "Error in script $0: incorrect first argument for start date (should be in form %Y-%M-%D)"
  echo ${Usage}
  exit 1
  
fi

end_seconds=`date -u -d "${end_date} 00:00 UTC" +'%s'`

if [[ $? != 0 || ${end_seconds}'X' == 'X' ]] ; then
  
  echo "Error in script $0: incorrect second argument for end date (should be in form %Y-%M-%D)"
  echo ${Usage}
  exit 1
  
fi

if [[ ${start_seconds} -gt ${end_seconds} ]] ; then
  
  echo "Error in script $0: end date is before the start date"
  echo ${Usage}
  exit 1
  
fi

echo "Start date is: ${start_date}"
echo "End   date is: ${end_date}"


# ------------------------------------------------------------------------------
#
#  **  User-specified parameters  **
#
# ------------------------------------------------------------------------------

# ----------------------------------------------------------------------
#  1)   NWP METEOROLOGY
# ----------------------------------------------------------------------

# Retention period for local NWP files
MetHistory=32

# Directory containing topography files
TopogSubdir='UMTopogData'


# ----------------------------------------------------------------------
#  2)   SOURCE LOCATION,  OUTPUT GRIDS  AND  MODELLING DOMAIN
# ----------------------------------------------------------------------

# Source: Mace Head (location in standard lat-lon coordinates)

Location='MCOH'
SourceLoc_X='73.18'
SourceLoc_Y='6.78'
SourceLoc_Z='15'
dZ='0'

# INDIANOCEAN
# Output Grid 1 and Grid 2
Grid1_nX=195
Grid1_nY=240
Grid1_dX='0.352'
Grid1_dY='0.234'
Grid1_Xmin='30'
Grid1_Ymin='-10'

# INDIANOCEAN  
# Computational domain (recommend 5 deg buffer (long) and 4 deg buffer (lat))
CompDom_Xmin='25'
CompDom_Xmax='100'
CompDom_Ymin='-14'
CompDom_Ymax='50'

# ----------------------------------------------------------------------
#  3)   DURATION OF SIMULATION (i.e. MAX PARTICLE AGE IN DAYS)
# ----------------------------------------------------------------------

MaxAge_Days=30


# ----------------------------------------------------------------------
#  4)   SAMPLING PERIOD FOR EACH BACK MAP (IN HOURS)
# ----------------------------------------------------------------------

# This should be a divisor of 24 (that is: 1, 2, 3, 4, 6, 8, 12 or 24)

SamplingPeriod_Hours=3


# ----------------------------------------------------------------------
#  5)   PARTICLE RELEASE AND SYNC TIME CHARACTERISTICS
# ----------------------------------------------------------------------

ParticlesPerSource='3333/hr'
MaxNumParticles=1000000

SyncTime_Minutes=15
nIntTimesPerHour=4

# ----------------------------------------------------------------------
#  6)   NAME OF RUN
# ----------------------------------------------------------------------

RunName=${Location}


# ----------------------------------------------------------------------
#  7)   CONTROL FLAGS FOR SCRIPT EXECUTION
# ----------------------------------------------------------------------

# Number of threads for parallelised NAME execution

let nThreads=1

# THE FOLLOWING OPTIONS WERE AVAILABLE IN ALISTAIR'S ORIGINAL SCRIPTS
# BUT HAVE NOT BEEN IMPLEMENTED HERE AS THE PRECISE DETAILS OF THE
# OUTPUTS AND PLOTS NEED TO BE DECIDED.

# Do not run NAME but instead copy existing results to be analysed 
# (graphics_only=1)

graphics_only=0

# Store data on /workspace
# (store_data=1)

store_data=1


# ----------------------------------------------------------------------
#  8)   SET DIRECTORIES
# ----------------------------------------------------------------------

SCRIPTDIR="$GWS/$USER/NAME_scripts"
NAMEIIIDIR="/data/shared/NAME/Model/NAMEIII_v6_5_particlelocation"

WORKDIR="$SCRIPTDIR/Results/${RunName}"
#STOREDIR="$SCRIPTDIR/Back_results"

METDIR="/data/$USER/met_data"
TOPOGDIR="/data/shared/NAME/Model/NAMEIII_v6_5_particlelocation/Resources/Topog"

# ------------------------------------------------------------------------------
#
#  Set up directory structures (if necessary) and switch to working directory
#
# ------------------------------------------------------------------------------

# Create working directory for NAME runs

mkdir -p ${WORKDIR}

# Create store directory for NAME runs

#mkdir -p ${STOREDIR}

# Create local met directory

mkdir -p ${METDIR}

# Switch to working directory

cd ${WORKDIR}


# ------------------------------------------------------------------------------
#
#  Calculate input file parameters from supplied user inputs
#
# ------------------------------------------------------------------------------

# max particle age in hours
let MaxAge_Hours=${MaxAge_Days}*24

# duration of run (24 hours longer than max particle age)
let RunDuration=${MaxAge_Hours}+24

# total number of integration steps for integrated air concentrations
let nIntTimes=${RunDuration}*${nIntTimesPerHour}

# Met input file
met_input_file="BackRun_${RunName}_met.txt"
cp  ${SCRIPTDIR}/Met_surface_template.txt  ${met_input_file}

# ------------------------------------------------------------------------------
#
#  Loop over dates from  start_date  to  end_date 
#
# ------------------------------------------------------------------------------

# Increment end_date by one day to ensure that NAME runs on end_date itself

end_date=`date -u -d "${end_date} +24 hour" +'%Y-%m-%d'`

# Initialise current date to the start date

cur_date=${start_date}

# Set counter for preparing met_input file
let TotalSamplingPeriod_Index=0


# Now repeat time loop until end_date is reached

until [[ ${cur_date} == ${end_date} ]] ; do
  
  cur_date_as_char=`date -u -d "${cur_date}" +'%Y%m%d'`
  
  # set start and end times for NAME run
  # backwards run - so start of run is chronologically later than end of run
  RunStartTime=`date -u -d "${cur_date} 00:00 UTC              +1 day" +'%d/%m/%Y %H:%M'`
  RunStopTime=` date -u -d "${cur_date} 00:00 UTC -${MaxAge_Days} day" +'%d/%m/%Y %H:%M'`
  
  # ... and in seconds format as ...
  RunStartSecs=`date -u -d "${cur_date} 00:00 UTC              +1 day" +'%s'`
  RunStopSecs=` date -u -d "${cur_date} 00:00 UTC -${MaxAge_Days} day" +'%s'`
  
  # next determine the 'Mk' of the Global met data
  GlobalMetDate=${RunStartSecs}
  get_Mk_Global
  RunStartMk=${GlobalMetMk}
  
#  GlobalMetDate=${RunStopSecs}
#  get_Mk_Global
#  RunStopMk=${GlobalMetMk}
  
  # 'Mk' should be the same throughout the NAME run
  # (might relax this condition later on, but this would make coding more complicated)
#  if [[ ${RunStartMk} -eq ${RunStopMk} ]] ; then
  GlobalMk=${RunStartMk}
#  else
#    echo "Error in script $0: the start and stop dates of the NAME run do not use the same 'Mk' Global met data"
#    exit 2
#  fi
  
  # set files for use of NWP meteorology
  MetDefnFile="${NAMEIIIDIR}/Resources/Defns/${MetDefnFileName[${GlobalMk}]}"
  MetDeclnFile="${SCRIPTDIR}/MetDeclarations/${MetDeclnFileName[${GlobalMk}]}"
  MetRestoreScript="${SCRIPTDIR}/MetRestore_JASMIN.ksh"
  
  # set input filename for NAME run
  input_file="BackRun_${RunName}_${cur_date_as_char}.txt"
  
  # set error filename for NAME run
  error_file="BackRun_${RunName}_${cur_date_as_char}Error.txt"
  
  # ----------------------------------------------------------------------------
  # Prepare main part of the input file
  # ----------------------------------------------------------------------------
  
  # copy main input file template for processing
  cp  ${SCRIPTDIR}/BackRuns_OneSite_ByDay_Template.txt  ${input_file}
  
  # substitute dynamic variables in the main part of the input file
  
  # - name of back run
  sed -i "s|%Run_Name%|${RunName}|g"             ${input_file}
  
  # - number of threads to use
  sed -i "s|%nThreads%|${nThreads}|g"            ${input_file}
  
  # - output directory
  sed -i "s|%OutputDir%|${WORKDIR}|g"            ${input_file}
  
  # - name of met defn file to read
  sed -i "s|%MetDefnFile%|${MetDefnFile}|g"      ${input_file}
  
  # - source location (as lat-long)
  sed -i "s|%SourceLoc_X%|${SourceLoc_X}|g"      ${input_file}
  sed -i "s|%SourceLoc_Y%|${SourceLoc_Y}|g"      ${input_file}
  
  # - duration of back run in hours
  sed -i "s|%RunDuration%|${RunDuration}|g"      ${input_file}
  
  # - start and end time
  sed -i "s|%StartTimeOfRun%|${RunStartTime}|g"  ${input_file}
  sed -i "s|%EndTimeOfRun%|${RunStopTime}|g"     ${input_file}
  
  # - sync time step (main model time step) in minutes
  sed -i "s|%SyncTime%|${SyncTime_Minutes}|g"    ${input_file}
  
  # - grid 1 definition
  sed -i "s|%Grid1_nX%|${Grid1_nX}|g"            ${input_file}
  sed -i "s|%Grid1_nY%|${Grid1_nY}|g"            ${input_file}
  sed -i "s|%Grid1_dX%|${Grid1_dX}|g"            ${input_file}
  sed -i "s|%Grid1_dY%|${Grid1_dY}|g"            ${input_file}
  sed -i "s|%Grid1_Xmin%|${Grid1_Xmin}|g"        ${input_file}
  sed -i "s|%Grid1_Ymin%|${Grid1_Ymin}|g"        ${input_file}
  
  # - grid 2 definition
  sed -i "s|%Grid2_nX%|${Grid2_nX}|g"            ${input_file}
  sed -i "s|%Grid2_nY%|${Grid2_nY}|g"            ${input_file}
  sed -i "s|%Grid2_dX%|${Grid2_dX}|g"            ${input_file}
  sed -i "s|%Grid2_dY%|${Grid2_dY}|g"            ${input_file}
  sed -i "s|%Grid2_Xmin%|${Grid2_Xmin}|g"        ${input_file}
  sed -i "s|%Grid2_Ymin%|${Grid2_Ymin}|g"        ${input_file}
  
  # - computational domain
  sed -i "s|%CompDom_Xmin%|${CompDom_Xmin}|g"    ${input_file}
  sed -i "s|%CompDom_Xmax%|${CompDom_Xmax}|g"    ${input_file}
  sed -i "s|%CompDom_Ymin%|${CompDom_Ymin}|g"    ${input_file}
  sed -i "s|%CompDom_Ymax%|${CompDom_Ymax}|g"    ${input_file}
  
  # - maximum number of particles allowed
  sed -i "s|%MaxNumParticles%|${MaxNumParticles}|g"  ${input_file}
  
    # - name of back run
  sed -i "s|%Run_Name%|${RunName}|g"             ${met_input_file}

  # - number of threads to use
  sed -i "s|%nThreads%|${nThreads}|g"            ${met_input_file}

  # - output directory
  sed -i "s|%OutputDir%|${WORKDIR}|g"            ${met_input_file}

  # - name of met defn file to read
  sed -i "s|%MetDefnFile%|${MetDefnFile}|g"      ${met_input_file}

  sed -i "s|%SyncTime%|${SyncTime_Minutes}|g"    ${met_input_file}

  sed -i "s|%CompDom_Xmin%|${CompDom_Xmin}|g"    ${met_input_file}
  sed -i "s|%CompDom_Xmax%|${CompDom_Xmax}|g"    ${met_input_file}
  sed -i "s|%CompDom_Ymin%|${CompDom_Ymin}|g"    ${met_input_file}
  sed -i "s|%CompDom_Ymax%|${CompDom_Ymax}|g"    ${met_input_file}
  sed -i "s|%CompDom_Ymax%|${CompDom_Ymax}|g"    ${met_input_file}

  sed -i "s|%StopTimeOfFlight%|${RunStartTime}|g"  ${met_input_file}
  sed -i "s|%StartTimeOfFlight%|${RunStopTime}|g"     ${met_input_file}

  
  # ----------------------------------------------------------------------------
  # Prepare sources and output requests for each sampling period
  # ----------------------------------------------------------------------------
  
  # loop through sampling periods on each day
  # backwards run - so start of each sampling period is chronologically later than end of period
  let SamplingPeriod_Index=0
  let hour_stop=0
  let hour_start=${SamplingPeriod_Hours}
  
  while [[ ${hour_stop} -lt 24 ]] ; do
    
    let SamplingPeriod_Index=${SamplingPeriod_Index}+1
    let TotalSamplingPeriod_Index=${TotalSamplingPeriod_Index}+1

    SamplingPeriod_Stop=` date -u -d "${cur_date} 00:00 UTC +${hour_stop}  hour" +'%d/%m/%Y %H:%M'`
    SamplingPeriod_Stop_as_char=`date -u -d "${cur_date} UTC +${hour_stop}  hour" +'%Y%m%d%H'`
    SamplingPeriod_Start=`date -u -d "${cur_date} 00:00 UTC +${hour_start} hour" +'%d/%m/%Y %H:%M'`
    
    # copy template for source and output requests block for processing
    cp  ${SCRIPTDIR}/SourceTermAndOutputRequests.txt  SourceAndRequests.tmp
    
    # substitute dynamic variables for this sampling period
    
    # - sample period index, start and end times
    sed -i "s|%SamplePeriod%|${SamplingPeriod_Index}|g"        SourceAndRequests.tmp
    sed -i "s|%SamplePeriod_Start%|${SamplingPeriod_Start}|g"  SourceAndRequests.tmp
    sed -i "s|%SamplePeriod_End%|${SamplingPeriod_Stop}|g"     SourceAndRequests.tmp
    
    sed -i "s|%SourceLoc_Z%|${SourceLoc_Z}|g"      SourceAndRequests.tmp
    sed -i "s|%dZ%|${dZ}|g"      SourceAndRequests.tmp

    # - number of particles released by each source
    sed -i "s|%nParticlesPerSource%|${ParticlesPerSource}|g"   SourceAndRequests.tmp
    
    # - duration of back run in hours
    sed -i "s|%RunDuration%|${RunDuration}|g"                  SourceAndRequests.tmp
    
    # - number of integrating times for output fields
    sed -i "s|%nIntTimes%|${nIntTimes}|g"                      SourceAndRequests.tmp
    
    # append the processed source and output requests to the main input file
    echo ''                   >> ${input_file}
    cat SourceAndRequests.tmp >> ${input_file}
    
    # remove temporary file
    rm SourceAndRequests.tmp
    
    cp  ${SCRIPTDIR}/MetOutputRequests_surface.txt  MetSourceAndRequests.tmp

    sed -i "s|%SamplePeriod%|${TotalSamplingPeriod_Index}|g"        MetSourceAndRequests.tmp
    sed -i "s|%SamplePeriod%|${TotalSamplingPeriod_Index}|g"        MetSourceAndRequests.tmp
    sed -i "s|%SamplePeriod%|${TotalSamplingPeriod_Index}|g"        MetSourceAndRequests.tmp
    sed -i "s|%SourceLoc_X%|${SourceLoc_X}|g"      MetSourceAndRequests.tmp
    sed -i "s|%SourceLoc_Y%|${SourceLoc_Y}|g"      MetSourceAndRequests.tmp
    sed -i "s|%SourceLoc_Z%|${SourceLoc_Z}|g"      MetSourceAndRequests.tmp
    sed -i "s|%StopTimeOfRun%|${SamplingPeriod_Stop}|g"      MetSourceAndRequests.tmp
    sed -i "s|%StopTimeOfRun_char%|${SamplingPeriod_Stop_as_char}|g"      MetSourceAndRequests.tmp

    # append the processed source and output requests to the main input file
    echo ''                   >> ${met_input_file}
    cat MetSourceAndRequests.tmp >> ${met_input_file}

    # remove temporary file
    rm MetSourceAndRequests.tmp

    
    let hour_stop=${hour_stop}+${SamplingPeriod_Hours}
    let hour_start=${hour_start}+${SamplingPeriod_Hours}
    
  done
  
  # ----------------------------------------------------------------------------
  # Prepare the met declaration file
  # ----------------------------------------------------------------------------
  
  # copy template for met declaration file for processing
  cp  ${MetDeclnFile}  MetDeclaration.tmp
  
  # substitute dynamic variables for the met declaration
  
  # - Path of local met directory
  sed -i "s|%MetDir%|${METDIR}|g"                      MetDeclaration.tmp
  
  # - Path of topography directory
  sed -i "s|%TopogDir%|${TOPOGDIR}|g"                  MetDeclaration.tmp
  
  # - Met restore script to use
  sed -i "s|%MetRestoreScript%|${MetRestoreScript}|g"  MetDeclaration.tmp
  
  # append the processed met declaration to the main input file
  echo ''                >> ${input_file}
  cat MetDeclaration.tmp >> ${input_file}
  
  # remove temporary file
  rm MetDeclaration.tmp
  
  # ----------------------------------------------------------------------------
  # Run NAME for this day
  # ----------------------------------------------------------------------------
  
  echo "=============================="
  echo "Running NAME for ${cur_date}"
  echo "=============================="
  
  ${NAMEIIIDIR}/Executables_Linux/nameiii_64bit_par.exe  ${input_file}
  
  # ----------------------------------------------------------------------------
  # Check for errors in NAME run
  # ----------------------------------------------------------------------------
  
  if [[ -r ${error_file} ]] ; then
    error_status=`cat ${error_file} | wc -c`
  else
    error_status=1
  fi
  
  if [[ ${error_status} -ne 0 ]] ; then
    
    echo "NAME error when running: ${input_file}" >> ${WORKDIR}/MainErrors.txt
    echo "Error file is reproduced below"         >> ${WORKDIR}/MainErrors.txt
    cat ${error_file}                             >> ${WORKDIR}/MainErrors.txt
    
  fi
  
  # ----------------------------------------------------------------------------
  # Generate graphics and other post-processing
  # ----------------------------------------------------------------------------
  
  # ----------------------------------------------------------------------------
  # Tidy up following the NAME run
  # ----------------------------------------------------------------------------
  
#  # remove old met data no longer needed (older than prescribed history)
#  old_met_date=`date -u -d "${cur_date} -${MetHistory} day" +'%Y%m%d'`
#  old_met_files="${MetPrefix[${GlobalMk}]}${old_met_date}*${MetSuffix[${GlobalMk}]}"
  
#  echo "Deleting old met files ${old_met_files}"
#  find ${METDIR} -name "${old_met_files}" -type f -delete

  #change timestamp of fields files to be the release time rather than end time
  mv -f Fields_grid1_* Fields_${RunName}_${cur_date_as_char}.txt
  mv -f Fields_gridBL_* Fields_BL_${RunName}_${cur_date_as_char}.txt
  gzip Fields*.txt
  
  # increment day loop
  cur_date=`date -u -d "${cur_date} +24 hour" +'%Y-%m-%d'`
  
  mv particle_location.txt particle_location_${RunName}_${cur_date_as_char}.txt
  gzip particle_location_${RunName}_${cur_date_as_char}.txt

  
done

echo "Script $0 completing at" `date`

# -------------------------------- END OF FIELDS GENERATION-------------------------------
# --------------------------------- GENERATE MET DATA -------------------------------------

  # copy template for met declaration file for processing
  cp  ${MetDeclnFile}  MetDeclaration.tmp

  # substitute dynamic variables for the met declaration

  # - Path of local met directory
  sed -i "s|%MetDir%|${METDIR}|g"                      MetDeclaration.tmp

  # - Path of topography directory
  sed -i "s|%TopogDir%|${TOPOGDIR}|g"                  MetDeclaration.tmp

  # - Met restore script to use
  sed -i "s|%MetRestoreScript%|${MetRestoreScript}|g"  MetDeclaration.tmp

  # append the processed met declaration to the main input file
  echo ''                >> ${met_input_file}
  cat MetDeclaration.tmp >> ${met_input_file}

  # remove temporary file
  rm MetDeclaration.tmp


  ${NAMEIIIDIR}/Executables_Linux/nameiii_64bit_par.exe  ${met_input_file}

  gzip Met_*
  rm -f particle_location.txt
  mkdir -p Met_${RunName}
  mv -f Met*.gz Met_${RunName}/.

  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Input_files
  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Fields_files
  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Fields_files_BL
  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Particle_files
  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Met
  mkdir -p ${SCRIPTDIR}/Results/${RunName}/Processed_Fields_files

  mv -f Fields*BL*gz ${SCRIPTDIR}/Results/${RunName}/Fields_files_BL/.
  mv -f Fields*gz ${SCRIPTDIR}/Results/${RunName}/Fields_files/.
  mv -f particle_location*gz ${SCRIPTDIR}/Results/${RunName}/Particle_files/.
  mv -f Met_${RunName}/* ${SCRIPTDIR}/Results/${RunName}/Met/.
  mv -f *.txt ${SCRIPTDIR}/Results/${RunName}/Input_files/.

  rm -r Met_${RunName}
  
  find ${SCRIPTDIR}/Results/${RunName}/ -type f -print0 | xargs -0 chmod 664
exit 0
