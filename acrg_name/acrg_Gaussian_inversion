#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Mon Jul 24 22:32:42 2017

@author: ag12733

Call analytical_inversion to run a Gaussian inversion

Uses the output file from name.merge_sensitivity

"""

import numpy as np
import pandas as pd
import pickle
from acrg_name.name import flux, basis
from acrg_grid import areagrid
import acrg_convert as unit_convert

def baseline(y, y_time, y_site, baseline_error = 100., days_to_average = 5.):
    """
    Prepares an add-on to the sensitivity (H) matrix, that allows the baseline
    to be solved within the inversion.
    
    Specify how many days of data you want the baseline to be solved for at a time.
    If this number will leave one or two days at the end of the month, these days
    will be added to the previous bucket. For example, a days_to_average value of 5
    might leave a 6 day long bucket at the end of the month.
    
    Also specify the error on x for the inversion.
    """
    keys = np.unique(y_site)

    n = float(days_to_average)
    pos = np.zeros(len(y))
    for site in keys:
        val = np.max(pos)
        wh = np.where(y_site == site)
        ts = pd.Series(1, y_time[wh])
        fiveday = np.clip((ts.index.day-1) // n, 0, n)
        months = (ts.index.month - ts.index.month[0])
        pos[wh] = (val + 1) + fiveday + months*(n+1)
    
    HB = np.zeros((len(y), len(np.unique(pos))))
    xerror = np.zeros(len(np.unique(pos)))
    col = 0
    for i in range(len(np.unique(pos))):
        wh = np.where(pos == i+1)
        HB[wh, col] = 1
        xerror[col] = float(baseline_error)
        col += 1
                
    return HB, xerror


def gauss_inversion(data, prior, model, data_error, prior_error):
    """
    Simple gaussian inversion. Inputs are required to be arrays,
    already in the correct dimensions for the inversion:
    data : (m,)
    prior : (n,)
    model : (m,n)
    data_error : (m,m)
    prior_error : (n,n)
    """
    if type(data) is not np.matrix:
        data = np.matrix(data)
    if type(prior) is not np.matrix:
        prior = np.matrix(prior)
    if type(model) is not np.matrix:
        model = np.matrix(model)
    if type(data_error) is not np.matrix:
        data_error = np.matrix(data_error)
    if type(prior_error) is not np.matrix:
        prior_error= np.matrix(prior_error)

    y = data.T
    xa = prior.T
    H = model
    R1 = data_error.I
    P1 = prior_error.I
    
    P = ((H.T*R1)*H + P1).I
    x = xa + P*H.T*R1*(y - H*xa)
        
    return x, P


def prior_flux(species, domain, basis_case, av_date, emissions_name = None):
    """
    Calculates an area weighted flux for each basis region using the prior emissions.
    'av_date' is a date representative of the timeseries being looked at. It is used
    to find the most appropriate flux and basis files. Will only work for a flux that
    doesn't change during the peirod of the inversion.
    
    WARNING! This has a bug at the moment, only finds the nearest flux or basis
    file ON OR BEFORE the inputted av_date.
    """

    if emissions_name == None:
        emissions_name = species

    flux_data= flux(domain, emissions_name)
    basis_data = basis(domain, basis_case)
    
    print av_date
    
    flux_timestamp = pd.DatetimeIndex(flux_data.time.values).asof(av_date)
    basis_timestamp = pd.DatetimeIndex(basis_data.time.values).asof(av_date)
    
    flux0 = flux_data.flux.sel(time=flux_timestamp).values
    basis0 = basis_data.basis.sel(time=basis_timestamp).values
    
    basis_nos = range(int(np.min(basis0)), int(np.max(basis0))+1)
    
    area = areagrid(flux_data.lat.values, flux_data.lon.values)
            
    awflux = flux0*area
    basisflux = np.zeros(np.shape(basis_nos))
        
    for i in basis_nos:
        basisflux[i-1] = np.sum(awflux[basis0[:,:]==i])

    prior_x = unit_convert.mol2kg(basisflux,species)*(3600*24*365)
    
    return prior_x
    
    
def scaling_to_post_flux(prior_x, x, P):
    """
    For Gaussian inversion will convert outputs (emission scaling factors and associated error)
    to emission estimates using the prior flux calculated using the function 'prior_flux'.
    """

    if type(x) is not np.array:
        x = np.array(x)
    x2 = x.reshape(np.shape(prior_x))

    post_x = np.array(x2)*prior_x

    qmatrix = np.zeros((len(post_x), len(post_x)))
    for i in range(len(post_x)):
        qmatrix[:,i] = post_x[:]*post_x[i]

    if type(P) is not np.array:
        P = np.array(P)
    V = np.array(P)*qmatrix
    uncert = sum(sum(V))**0.5
    
    return post_x, uncert


class analytical_inversion:
    def __init__(self, out_var_file, species, domain, basis_case='voronoi',
                 emissions_name = None, prior_error=1., baseline_error = 100., baseline_days = 5.):
        """
        Using the output file from merge_sensitivity will calculate emissions estimates
        using a Gaussian analyical inversion.
        
        x_error is percentage error for the emissions scaling factor (1 = 100% error).
        
        If H_bc exists (the boundary conditions have been found using vmrs from a global model)
        then there is no need to specify baseline_days, however baseline_error is still needed.
        
        species_key is used if the species name gives more information than just the species
        (e.g. ch4-fossil-fire : species is 'ch4-fossil-fire', species_key is 'ch4')
        """
        
        y, y_error, y_site, y_time, H_bc, H = pickle.load(open(out_var_file))
        
        x0 = np.ones(len(H[0,:]))
        
#       Solve for baseline
        if H_bc is not None:
            H = np.append(H, H_bc, axis=1)
            xerror_bl = np.ones(len(H_bc[0,:]))*float(baseline_error)
        else:
            H_bc, xerror_bl = baseline(y, y_time, y_site, baseline_error = baseline_error, days_to_average = baseline_days)
            H = np.append(H, H_bc, axis = 1)
        
        prior_bl = np.dot(H_bc,np.ones(len(H_bc[0,:])))
        
#       Inversion
        xa = np.append(x0,np.ones(len(xerror_bl)))
        xerror = np.ones(len(x0))*float(prior_error)
        P = np.diagflat(np.append(xerror**2, xerror_bl**2))
        if y_error == None:
            y_error = y*0.1
        
        R = np.diagflat(y_error**2)
        
        x, P = gauss_inversion(y, xa, H, R, P)      
        
#       Find middle time in y_time to get appropriate flux and basis year in scaling_to_emissions
        av_date = y_time[len(y_time)/2]
                
#       Find real emissions values
        prior = prior_flux(species, domain, basis_case, av_date, emissions_name = emissions_name)
        posterior, uncertainty = scaling_to_post_flux(prior, x[:len(x0)], P[:len(x0),:len(x0)])   
        
#       Find baseline solution
        BL = H[:,len(x0):]*x[len(x0):] #H[:,len(H_bc[0,:]):]*x[len(H_bc[0,:]):]
    
        self.prior_scal = xa
        self.model = H
        self.obs = y
        self.time = y_time
        self.site_code = y_site
        self.obs_error = y_error
        self.post_scal = x
        self.prior_emi = prior
        self.post_emi = posterior
        self.uncert = uncertainty
        self.prior_bl = prior_bl
        self.post_bl = BL

